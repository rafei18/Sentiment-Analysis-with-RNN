{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjNeaiPlNOoB",
        "outputId": "eb6802ca-8927-4ddb-a5ef-e501c8ce18e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 2.x  # this line is not required unless you are in a notebook\n",
        "from keras.datasets import imdb\n",
        "from keras.preprocessing import sequence\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "VOCAB_SIZE = 88584\n",
        "\n",
        "MAXLEN = 250\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words = VOCAB_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vHd_KZFNQeE",
        "outputId": "e1a1a791-69f1-426b-d011-45fa10c43a4f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(189, 218)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Lets look at one review\n",
        "len(train_data[1]), len(train_data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyrZYW4POHKp"
      },
      "source": [
        "###More Preprocessing\n",
        "We cannot pass different length data into our neural network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "CXT7Yjw7NZTx"
      },
      "outputs": [],
      "source": [
        "train_data = sequence.pad_sequences(train_data, MAXLEN)\n",
        "test_data = sequence.pad_sequences(test_data, MAXLEN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUbNF8TwOzCw"
      },
      "source": [
        "###Creating the Model\n",
        "We'll use a word embedding layer as the first layer in our model and add a LSTM layer afterwards that feeds into a dense node to get our predicted sentiment.\n",
        "\n",
        "32 stands for the output dimension of the vectors generated by the embedding layer. We can change this value if we'd like!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "1Fk7CvwCOnLe"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, 32),\n",
        "    tf.keras.layers.LSTM(32),\n",
        "    tf.keras.layers.Dense(1, activation=\"sigmoid\") # squishes the values between 0 and 1\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Az7usjDuO-vQ",
        "outputId": "c215b08c-e6f0-4818-b94e-5971ec08bff9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 32)          2834688   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 32)                8320      \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2843041 (10.85 MB)\n",
            "Trainable params: 2843041 (10.85 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LNtCqD_QLfR"
      },
      "source": [
        "###Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecLSbb8AP4eN",
        "outputId": "5d90e476-fef3-460e-d984-b4ed38f6822c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - 70s 109ms/step - loss: 0.4562 - acc: 0.7831 - val_loss: 0.2919 - val_acc: 0.8824\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 65s 104ms/step - loss: 0.2597 - acc: 0.8988 - val_loss: 0.4492 - val_acc: 0.8368\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 67s 107ms/step - loss: 0.1991 - acc: 0.9254 - val_loss: 0.2914 - val_acc: 0.8868\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 66s 105ms/step - loss: 0.1603 - acc: 0.9423 - val_loss: 0.3614 - val_acc: 0.8548\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 68s 109ms/step - loss: 0.1301 - acc: 0.9552 - val_loss: 0.3108 - val_acc: 0.8792\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 66s 106ms/step - loss: 0.1100 - acc: 0.9633 - val_loss: 0.3114 - val_acc: 0.8892\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 65s 104ms/step - loss: 0.0911 - acc: 0.9704 - val_loss: 0.3393 - val_acc: 0.8838\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 64s 103ms/step - loss: 0.0755 - acc: 0.9753 - val_loss: 0.3526 - val_acc: 0.8824\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 66s 106ms/step - loss: 0.0624 - acc: 0.9809 - val_loss: 0.3830 - val_acc: 0.8744\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 64s 103ms/step - loss: 0.0538 - acc: 0.9829 - val_loss: 0.4092 - val_acc: 0.8816\n"
          ]
        }
      ],
      "source": [
        "model.compile(loss=\"binary_crossentropy\",optimizer=\"rmsprop\",metrics=['acc'])\n",
        "\n",
        "history = model.fit(train_data, train_labels, epochs=10, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FDcSxPbQ-N6"
      },
      "source": [
        "And we'll evaluate the model on our training data to see how well it performs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EytY8ckQQQAA",
        "outputId": "44598d2a-94fe-44d1-ad45-85fd851d256c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 19s 25ms/step - loss: 0.4745 - acc: 0.8622\n",
            "[0.4744901657104492, 0.8621600270271301]\n"
          ]
        }
      ],
      "source": [
        "results = model.evaluate(test_data, test_labels)\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XU63cT7hRYbU"
      },
      "source": [
        "###Making Predictions\n",
        "Now letâ€™s use our network to make predictions on our own reviews.\n",
        "\n",
        "Since our reviews are encoded well need to convert any review that we write into that form so the network can understand it. To do that well load the encodings from the dataset and use them to encode our own data.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhGJqh_uRY4E",
        "outputId": "fd4b2c9c-0291-4578-e567-cd4f643868b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0  12  17  13  40 477  35 477]\n"
          ]
        }
      ],
      "source": [
        "word_index = imdb.get_word_index()\n",
        "def encode_text(text):\n",
        "  tokens = keras.preprocessing.text.text_to_word_sequence(text)\n",
        "  tokens = [word_index[word] if word in word_index else 0 for word in tokens]\n",
        "  return sequence.pad_sequences([tokens], MAXLEN)[0]\n",
        "\n",
        "text = \"that movie was just amazing, so amazing\"\n",
        "encoded = encode_text(text)\n",
        "print(encoded)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bl9sERfVUUTy"
      },
      "source": [
        "Decode function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ly27QDIZT7a0",
        "outputId": "b647d4f8-d547-45bd-f9e0-c1d95f8d0738"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "that movie was just amazing so amazing\n"
          ]
        }
      ],
      "source": [
        "\n",
        "reverse_word_index = {value: key for (key, value) in word_index.items()}\n",
        "\n",
        "def decode_integers(integers):\n",
        "    PAD = 0\n",
        "    text = \"\"\n",
        "    for num in integers:\n",
        "      if num != PAD:\n",
        "        text += reverse_word_index[num] + \" \"\n",
        "\n",
        "    return text[:-1]\n",
        "\n",
        "print(decode_integers(encoded))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_1mpp2bWYhW",
        "outputId": "c8efe40a-b78c-475a-d1e8-b20e9f17932e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 88ms/step\n",
            "[0.9596702]\n",
            "1/1 [==============================] - 0s 77ms/step\n",
            "[0.30503]\n"
          ]
        }
      ],
      "source": [
        "# now time to make a prediction\n",
        "\n",
        "def predict(text):\n",
        "  encoded_text = encode_text(text)\n",
        "  pred = np.zeros((1,250))\n",
        "  pred[0] = encoded_text\n",
        "  result = model.predict(pred)\n",
        "  print(result[0])\n",
        "\n",
        "positive_review = \"That movie was! really loved it and would great watch it again because it was amazingly great\"\n",
        "predict(positive_review)\n",
        "\n",
        "negative_review = \"that movie really sucked. I hated it and wouldn't watch it again. Was one of the worst things I've ever watched\"\n",
        "predict(negative_review)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
